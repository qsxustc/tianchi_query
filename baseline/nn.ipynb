{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "anyio                     4.7.0\n",
      "appnope                   0.1.4\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 3.0.0\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.2.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.2.0\n",
      "certifi                   2024.8.30\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.0\n",
      "comm                      0.2.2\n",
      "debugpy                   1.8.9\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.1.0\n",
      "fastjsonschema            2.21.1\n",
      "filelock                  3.16.1\n",
      "fqdn                      1.5.1\n",
      "fsspec                    2024.10.0\n",
      "gensim                    4.3.3\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.7\n",
      "httpx                     0.28.1\n",
      "huggingface-hub           0.26.5\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.30.0\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "jieba                     0.42.1\n",
      "Jinja2                    3.1.4\n",
      "json5                     0.10.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.2\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.2\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.0.2\n",
      "mpmath                    1.3.0\n",
      "nbclient                  0.10.1\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "notebook                  7.3.1\n",
      "notebook_shim             0.2.4\n",
      "numpy                     1.26.4\n",
      "overrides                 7.7.0\n",
      "packaging                 24.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.0.0\n",
      "pip                       24.2\n",
      "platformdirs              4.3.6\n",
      "prometheus_client         0.21.1\n",
      "prompt_toolkit            3.0.48\n",
      "psutil                    6.1.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "referencing               0.35.1\n",
      "regex                     2024.11.6\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.22.3\n",
      "safetensors               0.4.5\n",
      "scipy                     1.13.1\n",
      "Send2Trash                1.8.3\n",
      "setuptools                75.1.0\n",
      "six                       1.17.0\n",
      "smart-open                7.0.5\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.6\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.1\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.4.0\n",
      "tokenizers                0.21.0\n",
      "tomli                     2.2.1\n",
      "torch                     2.5.1\n",
      "torchaudio                2.5.1\n",
      "torchvision               0.20.1\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "transformers              4.47.0\n",
      "types-python-dateutil     2.9.0.20241206\n",
      "typing_extensions         4.12.2\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.3\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.11.1\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "wheel                     0.44.0\n",
      "wrapt                     1.17.0\n"
     ]
    }
   ],
   "source": [
    "# 查看当前kernel下已安装的包  list packages\n",
    "!pip list --format=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /opt/anaconda3/envs/query/lib/python3.10/site-packages (0.42.1)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/envs/query/lib/python3.10/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/anaconda3/envs/query/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/anaconda3/envs/query/lib/python3.10/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/envs/query/lib/python3.10/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/envs/query/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: dataclasses\n",
      "Successfully installed dataclasses-0.6\n"
     ]
    }
   ],
   "source": [
    "# 安装运行代码所需要的第三方包\n",
    "!pip install jieba --user\n",
    "!pip install gensim --user\n",
    "!pip install dataclasses --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-09 17:10:24--  https://ai.tencent.com/ailab/nlp/zh/data/tencent-ailab-embedding-zh-d100-v0.2.0-s.tar.gz\n",
      "正在解析主机 ai.tencent.com (ai.tencent.com)... 163.177.4.52\n",
      "正在连接 ai.tencent.com (ai.tencent.com)|163.177.4.52|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度：6840 (6.7K) [text/html]\n",
      "正在保存至: “tencent-ailab-embedding-zh-d100-v0.2.0-s.tar.gz”\n",
      "\n",
      "tencent-ailab-embed 100%[===================>]   6.68K  --.-KB/s  用时 0.04s     \n",
      "\n",
      "2024-12-09 17:10:24 (162 KB/s) - 已保存 “tencent-ailab-embedding-zh-d100-v0.2.0-s.tar.gz” [6840/6840])\n",
      "\n",
      "tar: Error opening archive: Unrecognized archive format\n"
     ]
    }
   ],
   "source": [
    "# 下载腾讯Lab词向量(v0.2.0, 100维-Small)\n",
    "!wget https://ai.tencent.com/ailab/nlp/zh/data/tencent-ailab-embedding-zh-d100-v0.2.0-s.tar.gz\n",
    "!tar -zxvf tencent-ailab-embedding-zh-d100-v0.2.0-s.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: output_data/: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir output_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import jieba\n",
    "import dataclasses\n",
    "import numpy as np\n",
    "import logging\n",
    "from dataclasses import field, dataclass\n",
    "from gensim.models import KeyedVectors\n",
    "from typing import List, Union, Dict, Any, Mapping, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "jieba.setLogLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InputExample:\n",
    "\n",
    "    guid: str\n",
    "    text_a: str\n",
    "    text_b: Optional[str] = None\n",
    "    label: Optional[str] = None\n",
    "\n",
    "    def to_json_string(self):\n",
    "        return json.dumps(dataclasses.asdict(self), indent=2) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "\n",
    "    w2v_file: str = field(\n",
    "        default='tencent-ailab-embedding-zh-d100-v0.2.0-s/tencent-ailab-embedding-zh-d100-v0.2.0-s.txt',\n",
    "        metadata={'help': 'The pretrained word2vec model directory'}\n",
    "    )\n",
    "    data_dir: str = field(\n",
    "        default='KUAKE-QQR',\n",
    "        metadata={'help': 'The data directory'}\n",
    "    )\n",
    "\n",
    "    def __str__(self):\n",
    "        self_as_dict = dataclasses.asdict(self)\n",
    "        attrs_as_str = [f\"{k}={v},\\n\" for k, v in sorted(self_as_dict.items())]\n",
    "        return f\"{self.__class__.__name__}(\\n{''.join(attrs_as_str)})\"\n",
    "        \n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(dataclasses.asdict(self), indent=2) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingArguments:\n",
    "\n",
    "    output_dir: str = field(\n",
    "        default='output_data/',\n",
    "        metadata={'help': 'The output directory where the model predictions and checkpoints will be written.'}\n",
    "    )\n",
    "    train_batch_size: int = field(\n",
    "        default=64,\n",
    "        metadata={'help': 'batch size for training'}\n",
    "    )\n",
    "    eval_batch_size: int = field(\n",
    "        default=64,\n",
    "        metadata={'help': 'batch size for evaluation'}\n",
    "    )\n",
    "    num_train_epochs: int = field(\n",
    "        default=27,\n",
    "        metadata={\"help\": \"The total number of training epochs\"}\n",
    "    )\n",
    "    learning_rate: float = field(\n",
    "        default=0.001,\n",
    "        metadata={'help': '\"The initial learning rate for AdamW.'}\n",
    "    )\n",
    "    weight_decay: float = field(\n",
    "        default=5e-4,\n",
    "        metadata={\"help\": \"Weight decay for AdamW\"}\n",
    "    )\n",
    "    logging_steps: int = field(\n",
    "        default=50,\n",
    "        metadata={'help': 'logging states every X updates steps.'}\n",
    "    )\n",
    "    eval_steps: int = field(\n",
    "        default=100,\n",
    "        metadata={'help': 'Run an evaluation every X steps.'}\n",
    "    )\n",
    "    device: str = field(\n",
    "        default='cpu',\n",
    "        metadata={\"help\": 'The device used for training'}\n",
    "    )\n",
    "\n",
    "    def __str__(self):\n",
    "        self_as_dict = dataclasses.asdict(self)\n",
    "        attrs_as_str = [f\"{k}={v},\\n\" for k, v in sorted(self_as_dict.items())]\n",
    "        return f\"{self.__class__.__name__}(\\n{''.join(attrs_as_str)})\"\n",
    "        \n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(dataclasses.asdict(self), indent=2) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArguments:\n",
    "\n",
    "    in_feat: int = field(\n",
    "        default=100,\n",
    "        metadata={'help': 'Size of input sample.'}\n",
    "    )\n",
    "    dropout_prob: float = field(\n",
    "        default=0.1,\n",
    "        metadata={'help': 'Dropout probability.'}\n",
    "    )\n",
    "\n",
    "    def __str__(self):\n",
    "        self_as_dict = dataclasses.asdict(self)\n",
    "        attrs_as_str = [f\"{k}={v},\\n\" for k, v in sorted(self_as_dict.items())]\n",
    "        return f\"{self.__class__.__name__}(\\n{''.join(attrs_as_str)})\"\n",
    "        \n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(dataclasses.asdict(self), indent=2) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QQRProcessor:\n",
    "    TASK = 'KUAKE-QQR'\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        self.task_dir = os.path.join(data_dir)\n",
    "\n",
    "    def get_train_examples(self):\n",
    "        return self._create_examples(os.path.join(self.task_dir, f'{self.TASK}_train.json'))\n",
    "\n",
    "    def get_dev_examples(self):\n",
    "        return self._create_examples(os.path.join(self.task_dir, f'{self.TASK}_dev.json'))\n",
    "\n",
    "    def get_test_examples(self):\n",
    "        return self._create_examples(os.path.join(self.task_dir, f'{self.TASK}_test.json'))\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\", \"2\"]\n",
    "\n",
    "    def _create_examples(self, data_path):\n",
    "\n",
    "        # 读入文件\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            samples = json.load(f)\n",
    "\n",
    "        examples = []\n",
    "        for sample in samples:\n",
    "            guid = sample['id']\n",
    "            text_a = sample['query1']\n",
    "            text_b = sample['query2']\n",
    "            label = sample.get('label', None)\n",
    "\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
    "\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QQRDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        examples: List[InputExample],\n",
    "        label_list: List[Union[str, int]],\n",
    "        vocab_mapping: Dict,\n",
    "        max_length: int = 64,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.examples = examples\n",
    "\n",
    "        self.vocab_mapping = vocab_mapping\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "        self.id2label = {idx: label for idx, label in enumerate(label_list)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        # 文本分词\n",
    "        tokens = list(jieba.cut(text))\n",
    "\n",
    "        token_ids = []\n",
    "        for token in tokens:\n",
    "            if token in self.vocab_mapping:\n",
    "                # 如果当前词存在于词表，将词转换为词的ID.\n",
    "                token_id = self.vocab_mapping[token]\n",
    "                token_ids.append(token_id)\n",
    "            else:\n",
    "                # OOV情况处理\n",
    "                # 如果该词为多字的词，将其拆分多个字，分别将这些字转换为相应的ID；\n",
    "                # 如果该词为单字，则从词表中随机采样一个词，其ID作为该词的ID\n",
    "                if len(token) > 1:\n",
    "                    for t in list(token):\n",
    "                        if t in self.vocab_mapping:\n",
    "                            token_ids.append(self.vocab_mapping[t])\n",
    "                        else:\n",
    "                            token_ids.append(np.random.choice(len(self.vocab_mapping), 1)[0])\n",
    "                else:\n",
    "                    token_ids.append(np.random.choice(len(self.vocab_mapping), 1)[0])\n",
    "\n",
    "        # 对文本进行填充或者截断\n",
    "        token_ids, attention_mask = self._pad_truncate(token_ids)\n",
    "        \n",
    "        return token_ids, attention_mask\n",
    "\n",
    "    def _pad_truncate(self, token_ids: List[int]):\n",
    "        # attention_mask作为标识文本填充情况\n",
    "        attention_mask = None\n",
    "\n",
    "        # 如果文本长度（以词为单位）大于设定的阈值，则截断末尾部分；\n",
    "        # 如果文本长度小于设定的阈值，则填充0\n",
    "        if len(token_ids) > self.max_length:\n",
    "            token_ids = token_ids[:self.max_length], \n",
    "            attention_mask = [1] * self.max_length\n",
    "        else:\n",
    "            attention_mask = [1] * len(token_ids)\n",
    "\n",
    "            diff = self.max_length - len(token_ids)\n",
    "            token_ids.extend([0] * diff)\n",
    "            attention_mask.extend([0] * diff)\n",
    "\n",
    "        return token_ids, attention_mask        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        example = self.examples[index]\n",
    "        label = None\n",
    "        # if example.label is not None:\n",
    "        #     label = self.label2id[example.label]\n",
    "        if example.label is None or example.label == '':\n",
    "            label = 0  # 测试集默认标签\n",
    "        else:\n",
    "            if example.label == 'NA':\n",
    "                example.label = '0'\n",
    "            label = self.label2id[example.label]\n",
    "\n",
    "        # tokenize\n",
    "        text_a_token_ids, text_a_attention_mask = self._tokenize(example.text_a)\n",
    "        text_b_token_ids, text_b_attention_mask = self._tokenize(example.text_b)\n",
    "\n",
    "        return {'text_a_input_ids': text_a_token_ids, 'text_b_input_ids': text_b_token_ids, \n",
    "                'text_a_attention_mask': text_a_attention_mask, 'text_b_attention_mask': text_b_attention_mask, 'label': label}\n",
    "\n",
    "\n",
    "class DataCollator:\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]):\n",
    "        \n",
    "        # 将一个batch内的样本输入转换为Tensor\n",
    "        \n",
    "        text_a_input_ids = []\n",
    "        text_b_input_ids = []\n",
    "        text_a_attention_mask = []\n",
    "        text_b_attention_mask = []\n",
    "        labels = []\n",
    "        for item in features:\n",
    "            text_a_input_ids.append(item['text_a_input_ids'])\n",
    "            text_b_input_ids.append(item['text_b_input_ids'])\n",
    "            text_a_attention_mask.append(item['text_a_attention_mask'])\n",
    "            text_b_attention_mask.append(item['text_b_attention_mask'])\n",
    "            if item['label'] is not None:\n",
    "                labels.append(item['label'])\n",
    "        \n",
    "        text_a_input_ids = torch.tensor(text_a_input_ids, dtype=torch.long)\n",
    "        text_b_input_ids = torch.tensor(text_b_input_ids, dtype=torch.long)\n",
    "        text_a_attention_mask = torch.tensor(text_a_attention_mask, dtype=torch.bool)\n",
    "        text_b_attention_mask = torch.tensor(text_b_attention_mask, dtype=torch.bool)\n",
    "        if len(labels) > 0:\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        return {'text_a_input_ids': text_a_input_ids, 'text_b_input_ids': text_b_input_ids, \n",
    "                'text_a_attention_mask': text_a_attention_mask, 'text_b_attention_mask': text_b_attention_mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat: int = 100, dropout_prob: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense1 = nn.Linear(in_feat, in_feat)\n",
    "        self.dense2 = nn.Linear(in_feat, in_feat)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, token_embeds, attention_mask):\n",
    "        batch_size = token_embeds.size(0)\n",
    "        \n",
    "        # 进行Mean pooling操作，即简单地将文本的词向量求和\n",
    "        x = torch.stack([token_embeds[i, attention_mask[i, :], :].sum(dim=0) for i in range(batch_size)], dim=0)\n",
    "\n",
    "        x = self.act(self.dense1(x))\n",
    "        x = self.act(self.dense2(self.dropout(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat, num_labels: int, dropout_prob: float = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense1 = nn.Linear(in_feat, in_feat // 2)\n",
    "        self.dense2 = nn.Linear(in_feat // 2, num_labels)\n",
    "        self.act = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.act(self.dense1(self.dropout(x)))\n",
    "        x = self.dense2(self.dropout(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SemNN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_feat: int = 100,\n",
    "        num_labels: int = 3,\n",
    "        dropout_prob: float = 0.1,\n",
    "        w2v_state_dict: torch.Tensor = None,\n",
    "        vocab_size: int = None,\n",
    "        word_embedding_dim: int = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self._init_word_embedding(w2v_state_dict, vocab_size, word_embedding_dim)\n",
    "        \n",
    "        self.encoder = Encoder(in_feat=in_feat)\n",
    "        self.classifier = Classifier(in_feat=2*in_feat, num_labels=num_labels, dropout_prob=dropout_prob)\n",
    "\n",
    "    def _init_word_embedding(self, state_dict=None, vocab_size=None, word_embedding_dim=None):\n",
    "        if state_dict is None:\n",
    "            self.word_embedding = nn.Embedding(vocab_size, word_embedding_dim, padding_idx=0)\n",
    "        else:\n",
    "            # 默认载入预训练好的词向量（且固定词向量），并将其第一个词作为填充词（以及其对应向量设为零向量）\n",
    "            state_dict = torch.tensor(state_dict.vectors, dtype=torch.float32)\n",
    "            state_dict[0] = torch.zeros(state_dict.size(-1))\n",
    "            self.word_embedding = nn.Embedding.from_pretrained(state_dict, freeze=True, padding_idx=0)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        text_a_input_ids,\n",
    "        text_b_input_ids,\n",
    "        text_a_attention_mask,\n",
    "        text_b_attention_mask, \n",
    "        labels=None\n",
    "    ):\n",
    "        # 将两个query的词ID转换为其相应的词向量\n",
    "        text_a_vecs = self.word_embedding(text_a_input_ids)\n",
    "        text_b_vecs = self.word_embedding(text_b_input_ids)\n",
    "\n",
    "        # 通过Encoder得到两个query的向量表示\n",
    "        text_a_vec = self.encoder(text_a_vecs, text_a_attention_mask)\n",
    "        text_b_vec = self.encoder(text_b_vecs, text_b_attention_mask)\n",
    "\n",
    "        # 拼接两个Query的表示，再输入到分类器中\n",
    "        pooler_output = torch.cat([text_a_vec, text_b_vec], dim=-1)\n",
    "        logits = self.classifier(pooler_output)\n",
    "        \n",
    "        # 训练过程中的Loss计算\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return (loss, logits) if loss is not None else logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer_and_lr_scheduler(\n",
    "    args: TrainingArguments,\n",
    "    model: nn.Module\n",
    "):\n",
    "    # 构建优化器\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(), \n",
    "        lr=args.learning_rate,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "    # 构建学习率调度器\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2, eta_min=1e-5)\n",
    "\n",
    "    return optimizer, lr_scheduler\n",
    "\n",
    "\n",
    "def _prepare_input(data: Union[torch.Tensor, Any], device: str = 'cuda'):\n",
    "    # 将准备输入模型中的数据转到GPU上\n",
    "    if isinstance(data, Mapping):\n",
    "        return type(data)({k: _prepare_input(v, device) for k, v in data.items()})\n",
    "    elif isinstance(data, (tuple, list)):\n",
    "        return type(data)(_prepare_input(v, device) for v in data)\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        kwargs = dict(device=device)\n",
    "        return data.to(**kwargs)\n",
    "    return data\n",
    "\n",
    "\n",
    "def simple_accuracy(preds, labels):\n",
    "\n",
    "    return (preds == labels).mean()\n",
    "    \n",
    "\n",
    "def evaluate(\n",
    "    args: TrainingArguments,\n",
    "    model: nn.Module,\n",
    "    eval_dataloader\n",
    "):\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    preds_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for item in eval_dataloader:\n",
    "        inputs = _prepare_input(item, device=args.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "\n",
    "            preds = torch.argmax(outputs[1].cpu(), dim=-1).numpy()\n",
    "            preds_list.append(preds)\n",
    "\n",
    "            labels_list.append(inputs['labels'].cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    loss = np.mean(loss_list)\n",
    "    accuracy = simple_accuracy(preds, labels)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def train(\n",
    "    args: TrainingArguments,\n",
    "    model: nn.Module,\n",
    "    train_dataset,\n",
    "    dev_dataset,\n",
    "    data_collator,\n",
    "):\n",
    "\n",
    "    # initialize dataloader\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset, \n",
    "        batch_size=args.train_batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "    dev_dataloader = DataLoader(\n",
    "        dataset=dev_dataset,\n",
    "        batch_size=args.eval_batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    num_examples = len(train_dataloader.dataset)\n",
    "    num_update_steps_per_epoch = len(train_dataloader)\n",
    "    num_update_steps_per_epoch = max(num_update_steps_per_epoch, 1)\n",
    "    \n",
    "    max_steps = math.ceil(args.num_train_epochs * num_update_steps_per_epoch)\n",
    "    num_train_epochs = math.ceil(args.num_train_epochs)\n",
    "    num_train_samples = len(train_dataset) * args.num_train_epochs\n",
    "\n",
    "    optimizer, lr_scheduler = create_optimizer_and_lr_scheduler(args, model)\n",
    "\n",
    "    print(\"***** Running training *****\")\n",
    "    print(f\"  Num examples = {num_examples}\")\n",
    "    print(f\"  Num Epochs = {args.num_train_epochs}\")\n",
    "    print(f\"  Instantaneous batch size per device = {args.train_batch_size}\")\n",
    "    print(f\"  Total train batch size (w. parallel, distributed & accumulation) = {args.train_batch_size}\")\n",
    "    print(f\"  Total optimization steps = {max_steps}\")\n",
    "\n",
    "    model.zero_grad()\n",
    "    model.train()\n",
    "    global_steps = 0\n",
    "\n",
    "    best_metric = 0.0\n",
    "    best_steps = -1\n",
    "\n",
    "    for epoch in range(num_train_epochs):\n",
    "        for step, item in enumerate(train_dataloader):\n",
    "            inputs = _prepare_input(item, device=args.device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step(epoch + step / num_update_steps_per_epoch)\n",
    "\n",
    "            model.zero_grad()\n",
    "            global_steps += 1\n",
    "\n",
    "            if global_steps % args.logging_steps == 0:\n",
    "                print(f'Training: Epoch {epoch + 1}/{num_train_epochs} - Step {(step + 1)} - Loss {loss}')\n",
    "\n",
    "            if global_steps % args.eval_steps == 0:\n",
    "                \n",
    "                loss, acc = evaluate(args, model, dev_dataloader)\n",
    "                print(f'Evaluation: Epoch {epoch + 1}/{num_train_epochs} - Step {(global_steps + 1)} - Loss {loss} - Accuracy {acc}')\n",
    "\n",
    "                if acc > best_metric:\n",
    "                    best_metric = acc\n",
    "                    best_steps = global_steps\n",
    "                    \n",
    "                    saved_path = os.path.join(args.output_dir, f'checkpoint-{best_steps}.pt')\n",
    "                    torch.save(model.state_dict(), saved_path)\n",
    "\n",
    "    return best_steps, best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    args: TrainingArguments,\n",
    "    model: nn.Module,\n",
    "    test_dataset,\n",
    "    data_collator\n",
    "):\n",
    "    # 初始化DataLoader\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=args.eval_batch_size, \n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "\n",
    "    print(\"***** Running prediction *****\")\n",
    "    print(f\"  Num examples = {len(test_dataset)}\")\n",
    "    print(f\"  Batch size = {args.eval_batch_size}\")\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    # 逐批次预测\n",
    "    for batch in test_dataloader:\n",
    "        batch = _prepare_input(batch, device=args.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs[1] if isinstance(outputs, tuple) else outputs\n",
    "            pred = torch.argmax(logits, dim=-1)\n",
    "            predictions.extend(pred.cpu().numpy().tolist())\n",
    "            \n",
    "    model.train()\n",
    "    \n",
    "    # 将数字标签映射回原始标签\n",
    "    predictions = [test_dataset.id2label[pred] for pred in predictions]\n",
    "    \n",
    "    print(f\"Prediction finished, total predictions: {len(predictions)}\")\n",
    "    return predictions\n",
    "\n",
    "def generate_commit(output_dir, task_name, test_dataset, predictions):\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 整合预测结果\n",
    "    results = []\n",
    "    for example, pred_label in zip(test_dataset.examples, predictions):\n",
    "        result = {\n",
    "            \"id\": example.guid,\n",
    "            \"query1\": example.text_a,\n",
    "            \"query2\": example.text_b,\n",
    "            \"label\": pred_label\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    # 保存结果\n",
    "    output_file = os.path.join(output_dir, f'{task_name}_test.json') \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataTrainingArguments(\n",
      "data_dir=KUAKE-QQR,\n",
      "w2v_file=tencent-ailab-embedding-zh-d100-v0.2.0-s/tencent-ailab-embedding-zh-d100-v0.2.0-s.txt,\n",
      ")\n",
      "TrainingArguments(\n",
      "device=cpu,\n",
      "eval_batch_size=64,\n",
      "eval_steps=100,\n",
      "learning_rate=0.001,\n",
      "logging_steps=50,\n",
      "num_train_epochs=27,\n",
      "output_dir=output_data/,\n",
      "train_batch_size=64,\n",
      "weight_decay=0.0005,\n",
      ")\n",
      "ModelArguments(\n",
      "dropout_prob=0.1,\n",
      "in_feat=100,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "data_args = DataTrainingArguments()\n",
    "training_args = TrainingArguments()\n",
    "model_args = ModelArguments()\n",
    "print(data_args)\n",
    "print(training_args)\n",
    "print(model_args)\n",
    "\n",
    "#载入词向量\n",
    "w2v_model = KeyedVectors.load_word2vec_format(data_args.w2v_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = QQRProcessor(data_dir=data_args.data_dir)\n",
    "\n",
    "train_dataset = QQRDataset(\n",
    "    processor.get_train_examples(), \n",
    "    processor.get_labels(),\n",
    "    vocab_mapping=w2v_model.key_to_index,\n",
    "    max_length=32\n",
    ")\n",
    "eval_dataset = QQRDataset(\n",
    "    processor.get_dev_examples(),\n",
    "    processor.get_labels(),\n",
    "    vocab_mapping=w2v_model.key_to_index,\n",
    "    max_length=32\n",
    ")\n",
    "test_dataset = QQRDataset(\n",
    "    processor.get_test_examples(),\n",
    "    processor.get_labels(),\n",
    "    vocab_mapping=w2v_model.key_to_index,\n",
    "    max_length=32\n",
    ")\n",
    "\n",
    "data_collator = DataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建输出结果（模型、参数、预测结果）的文件夹\n",
    "model_name = f'semnn-{str(int(time.time()))}'\n",
    "training_args.output_dir = os.path.join(training_args.output_dir, model_name)\n",
    "if not os.path.exists(training_args.output_dir):\n",
    "    os.makedirs(training_args.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SemNN(\n",
       "  (word_embedding): Embedding(2000000, 100, padding_idx=0)\n",
       "  (encoder): Encoder(\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (dense2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (act): Tanh()\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (dense1): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (dense2): Linear(in_features=100, out_features=3, bias=True)\n",
       "    (act): Tanh()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化模型\n",
    "print('Initialize model')\n",
    "model = SemNN(\n",
    "    in_feat=model_args.in_feat, \n",
    "    num_labels=len(processor.get_labels()), \n",
    "    dropout_prob=model_args.dropout_prob,\n",
    "    w2v_state_dict=w2v_model,\n",
    ")\n",
    "model.to(training_args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "***** Running training *****\n",
      "  Num examples = 15000\n",
      "  Num Epochs = 27\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Total optimization steps = 6345\n",
      "Training: Epoch 1/27 - Step 50 - Loss 0.8645390868186951\n",
      "Training: Epoch 1/27 - Step 100 - Loss 0.8376542925834656\n",
      "Evaluation: Epoch 1/27 - Step 101 - Loss 0.8075150513648987 - Accuracy 0.664375\n",
      "Training: Epoch 1/27 - Step 150 - Loss 0.8339117169380188\n",
      "Training: Epoch 1/27 - Step 200 - Loss 0.7950250506401062\n",
      "Evaluation: Epoch 1/27 - Step 201 - Loss 0.8182623481750488 - Accuracy 0.639375\n",
      "Training: Epoch 2/27 - Step 15 - Loss 0.6882098317146301\n",
      "Training: Epoch 2/27 - Step 65 - Loss 0.9125463962554932\n",
      "Evaluation: Epoch 2/27 - Step 301 - Loss 0.8144591212272644 - Accuracy 0.63875\n",
      "Training: Epoch 2/27 - Step 115 - Loss 0.6464906930923462\n",
      "Training: Epoch 2/27 - Step 165 - Loss 0.7004722356796265\n",
      "Evaluation: Epoch 2/27 - Step 401 - Loss 0.8318505442142486 - Accuracy 0.639375\n",
      "Training: Epoch 2/27 - Step 215 - Loss 0.6352139711380005\n",
      "Training: Epoch 3/27 - Step 30 - Loss 0.8258756995201111\n",
      "Evaluation: Epoch 3/27 - Step 501 - Loss 0.8075448966026306 - Accuracy 0.651875\n",
      "Training: Epoch 3/27 - Step 80 - Loss 0.767569899559021\n",
      "Training: Epoch 3/27 - Step 130 - Loss 0.7810125350952148\n",
      "Evaluation: Epoch 3/27 - Step 601 - Loss 0.8106291055679321 - Accuracy 0.65125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m best_steps, best_metric \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdev_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Finished! Best step - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Best accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(training_args\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 116\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, model, train_dataset, dev_dataset, data_collator)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m    115\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m _prepare_input(item, device\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 116\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    119\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/query/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/query/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 82\u001b[0m, in \u001b[0;36mSemNN.forward\u001b[0;34m(self, text_a_input_ids, text_b_input_ids, text_a_attention_mask, text_b_attention_mask, labels)\u001b[0m\n\u001b[1;32m     79\u001b[0m text_b_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embedding(text_b_input_ids)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# 通过Encoder得到两个query的向量表示\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m text_a_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_a_vecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_a_attention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m text_b_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(text_b_vecs, text_b_attention_mask)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# 拼接两个Query的表示，再输入到分类器中\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/query/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/query/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, token_embeds, attention_mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m token_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 进行Mean pooling操作，即简单地将文本的词向量求和\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([token_embeds[i, attention_mask[i, :], :]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense1(x))\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)))\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m token_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 进行Mean pooling操作，即简单地将文本的词向量求和\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mtoken_embeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense1(x))\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "print('Training...')\n",
    "best_steps, best_metric = train(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    dev_dataset=eval_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print(f'Training Finished! Best step - {best_steps} - Best accuracy {best_metric}')\n",
    "\n",
    "best_model_path = os.path.join(training_args.output_dir, f'checkpoint-{best_steps}.pt')\n",
    "model = SemNN(\n",
    "    in_feat=model_args.in_feat, \n",
    "    num_labels=len(processor.get_labels()), \n",
    "    dropout_prob=model_args.dropout_prob,\n",
    "    w2v_state_dict=w2v_model,\n",
    ")\n",
    "model.load_state_dict(torch.load(best_model_path, map_location='cpu'))\n",
    "model.to(training_args.device)\n",
    "\n",
    "# 保存最佳模型及超参数\n",
    "torch.save(model.state_dict(), os.path.join(training_args.output_dir, 'pytorch_model.bin'))\n",
    "torch.save(training_args, os.path.join(training_args.output_dir, 'training_args.bin'))\n",
    "\n",
    "# 预测及生成预测结果（供提交到平台）\n",
    "preds = predict(training_args, model, test_dataset, data_collator)\n",
    "generate_commit(training_args.output_dir, processor.TASK, test_dataset, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "query",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [
    {
     "id": "134026",
     "title": "【NLP】医学搜索Query相关性判断"
    }
   ],
   "description": "",
   "notebookId": "391814",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
